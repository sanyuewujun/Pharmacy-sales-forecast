{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 便利店销量预测\n",
    "这是[便利店销量预测比赛](https://www.kaggle.com/c/rossmann-store-sales)的一个简单尝试参考。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"page-name\">\n",
    "    Forecast sales using store, promotion, and competitor data\n",
    "</h1>\n",
    "\n",
    "\n",
    "<p>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, <br />Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.</p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\">In their first Kaggle competition, Rossmann is challenging you to predict 6 weeks of daily sales for 1,115 stores located across Germany. Reliable sales forecasts enable store managers to create effective staff schedules that increase productivity and motivation. By helping Rossmann create a robust prediction model, you will help store managers stay focused on what’s most important to them: their customers and their teams! </span></p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\"> <img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4594/media/rossmann_banner2.png\" alt=\"\" height=\"81\" width=\"640\" /><br /></span></p>\n",
    "<p><em><span style=\"font-size: 1em; line-height: 1.5em;\">If you are interested in joining Rossmann at their headquarters near Hanover, Germany, please contact Mr. Frank König (Frank.Koenig {at} rossmann.de) Rossmann is currently recruiting data scientists at <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=3A5205E3-C4F9-4F5D-AA93-438D0B064D70~\">senior</a> and <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=F5142F37-C823-4767-B7CF-21DE3B351D66~\">entry-level</a> positions.</span></em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据\n",
    "<table id=\"data-files\" class=\"nicetable full roomy align-top border\">   \n",
    "<thead>\n",
    "    <tr>\n",
    "        <th colspan=\"2\">File Name</th> \n",
    "        <th>Available Formats</th>         \n",
    "    </tr> \n",
    "</thead>\n",
    "\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">sample_submission.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/sample_submission.csv.zip\" name=\"sample_submission.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (55.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">store.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/store.csv.zip\" name=\"store.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (8.33 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">test.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/test.csv.zip\" name=\"test.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (143.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">train.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/train.csv.zip\" name=\"train.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (5.66 mb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Files</h3>\n",
    "<ul>\n",
    "<li><strong>train.csv</strong> - historical data including Sales</li>\n",
    "<li><strong>test.csv</strong> - historical data excluding Sales</li>\n",
    "<li><strong>sample_submission.csv</strong> - a sample submission file in the correct format</li>\n",
    "<li><strong>store.csv</strong> - supplemental information about the stores</li>\n",
    "</ul>\n",
    "<h3>Data fields</h3>\n",
    "<p>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "<ul>\n",
    "<li><strong>Id</strong> - an Id that represents a (Store, Date) duple within the test set</li>\n",
    "<li><strong>Store</strong> - a unique Id for each store</li>\n",
    "<li><strong>Sales</strong> - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li><strong>Customers</strong> - the number of customers on a given day</li>\n",
    "<li><strong>Open</strong> - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li><strong>StateHoliday</strong> - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li><strong>SchoolHoliday</strong> - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li><strong>StoreType</strong> - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li><strong>Assortment</strong> - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li><strong>CompetitionDistance</strong> - distance in meters to the nearest competitor store</li>\n",
    "<li><strong>CompetitionOpenSince[Month/Year]</strong> - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li><strong>Promo</strong> - indicates whether a store is running a promo on that day</li>\n",
    "<li><strong>Promo2</strong> - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li><strong>Promo2Since[Year/Week]</strong> - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li><strong>PromoInterval</strong> - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import model_selection\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.pyplot as pltt\n",
    "%matplotlib inline\n",
    "\n",
    "plot = True\n",
    "\n",
    "goal = 'Sales'\n",
    "myid = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一些变换和评判准则\n",
    "使用不同的loss function的时候要特别注意这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('./data/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales\n",
       "0        172871\n",
       "5674        215\n",
       "5558        197\n",
       "5483        196\n",
       "6049        195\n",
       "          ...  \n",
       "23861         1\n",
       "22756         1\n",
       "24520         1\n",
       "24144         1\n",
       "24287         1\n",
       "Name: count, Length: 21734, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sales'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open\n",
       "1    844392\n",
       "0    172817\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.72877e+05, 1.07000e+02, 6.20000e+02, 1.89600e+03, 4.13000e+03,\n",
       "        8.39000e+03, 1.41860e+04, 2.16560e+04, 3.14910e+04, 4.13200e+04,\n",
       "        4.93110e+04, 5.53090e+04, 5.84920e+04, 5.91820e+04, 5.79320e+04,\n",
       "        5.40820e+04, 4.93650e+04, 4.49760e+04, 4.12180e+04, 3.56050e+04,\n",
       "        3.09410e+04, 2.65370e+04, 2.31100e+04, 1.95920e+04, 1.69870e+04,\n",
       "        1.44620e+04, 1.21680e+04, 1.02250e+04, 8.60900e+03, 7.16100e+03,\n",
       "        6.04700e+03, 5.08100e+03, 4.37100e+03, 3.73900e+03, 3.23900e+03,\n",
       "        2.79300e+03, 2.41100e+03, 2.03900e+03, 1.84100e+03, 1.67300e+03,\n",
       "        1.45600e+03, 1.20800e+03, 1.10900e+03, 1.03500e+03, 9.09000e+02,\n",
       "        7.95000e+02, 7.42000e+02, 6.14000e+02, 5.48000e+02, 4.85000e+02,\n",
       "        4.15000e+02, 3.52000e+02, 3.38000e+02, 2.56000e+02, 2.61000e+02,\n",
       "        2.03000e+02, 1.83000e+02, 1.39000e+02, 9.90000e+01, 1.16000e+02,\n",
       "        9.20000e+01, 6.70000e+01, 7.10000e+01, 6.10000e+01, 7.30000e+01,\n",
       "        4.50000e+01, 4.00000e+01, 5.00000e+01, 3.30000e+01, 3.30000e+01,\n",
       "        2.80000e+01, 2.40000e+01, 2.80000e+01, 1.90000e+01, 1.50000e+01,\n",
       "        1.90000e+01, 1.40000e+01, 1.30000e+01, 8.00000e+00, 6.00000e+00,\n",
       "        3.00000e+00, 8.00000e+00, 3.00000e+00, 3.00000e+00, 3.00000e+00,\n",
       "        3.00000e+00, 1.00000e+00, 2.00000e+00, 0.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00, 2.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([    0.  ,   415.51,   831.02,  1246.53,  1662.04,  2077.55,\n",
       "         2493.06,  2908.57,  3324.08,  3739.59,  4155.1 ,  4570.61,\n",
       "         4986.12,  5401.63,  5817.14,  6232.65,  6648.16,  7063.67,\n",
       "         7479.18,  7894.69,  8310.2 ,  8725.71,  9141.22,  9556.73,\n",
       "         9972.24, 10387.75, 10803.26, 11218.77, 11634.28, 12049.79,\n",
       "        12465.3 , 12880.81, 13296.32, 13711.83, 14127.34, 14542.85,\n",
       "        14958.36, 15373.87, 15789.38, 16204.89, 16620.4 , 17035.91,\n",
       "        17451.42, 17866.93, 18282.44, 18697.95, 19113.46, 19528.97,\n",
       "        19944.48, 20359.99, 20775.5 , 21191.01, 21606.52, 22022.03,\n",
       "        22437.54, 22853.05, 23268.56, 23684.07, 24099.58, 24515.09,\n",
       "        24930.6 , 25346.11, 25761.62, 26177.13, 26592.64, 27008.15,\n",
       "        27423.66, 27839.17, 28254.68, 28670.19, 29085.7 , 29501.21,\n",
       "        29916.72, 30332.23, 30747.74, 31163.25, 31578.76, 31994.27,\n",
       "        32409.78, 32825.29, 33240.8 , 33656.31, 34071.82, 34487.33,\n",
       "        34902.84, 35318.35, 35733.86, 36149.37, 36564.88, 36980.39,\n",
       "        37395.9 , 37811.41, 38226.92, 38642.43, 39057.94, 39473.45,\n",
       "        39888.96, 40304.47, 40719.98, 41135.49, 41551.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pltt.hist(train_df['Sales'], bins=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.0000e+00, 7.0000e+00, 7.0000e+00, 1.1000e+01, 1.5000e+01,\n",
       "        3.1000e+01, 1.8000e+01, 2.9000e+01, 3.4000e+01, 5.4000e+01,\n",
       "        1.0300e+02, 1.3500e+02, 1.8700e+02, 2.2300e+02, 3.5300e+02,\n",
       "        4.2700e+02, 5.5000e+02, 6.3200e+02, 9.1600e+02, 1.3140e+03,\n",
       "        1.7280e+03, 2.3680e+03, 3.1540e+03, 4.4120e+03, 5.6570e+03,\n",
       "        7.5640e+03, 9.8170e+03, 1.2837e+04, 1.6868e+04, 2.2068e+04,\n",
       "        2.7077e+04, 3.3268e+04, 3.8761e+04, 4.4885e+04, 5.0245e+04,\n",
       "        5.4024e+04, 5.7061e+04, 5.6943e+04, 5.5599e+04, 5.3498e+04,\n",
       "        5.0144e+04, 4.4320e+04, 3.8481e+04, 3.2666e+04, 2.7452e+04,\n",
       "        2.1868e+04, 1.6902e+04, 1.2754e+04, 9.5910e+03, 7.3440e+03,\n",
       "        5.4430e+03, 4.2900e+03, 3.1430e+03, 2.4540e+03, 1.7300e+03,\n",
       "        1.1460e+03, 7.3000e+02, 3.8000e+02, 2.6200e+02, 1.6700e+02,\n",
       "        1.0500e+02, 4.6000e+01, 1.9000e+01, 1.0000e+01, 1.0000e+00]),\n",
       " array([ 3.8286414 ,  3.89670175,  3.96476211,  4.03282246,  4.10088282,\n",
       "         4.16894317,  4.23700352,  4.30506388,  4.37312423,  4.44118459,\n",
       "         4.50924494,  4.5773053 ,  4.64536565,  4.71342601,  4.78148636,\n",
       "         4.84954672,  4.91760707,  4.98566743,  5.05372778,  5.12178814,\n",
       "         5.18984849,  5.25790885,  5.3259692 ,  5.39402955,  5.46208991,\n",
       "         5.53015026,  5.59821062,  5.66627097,  5.73433133,  5.80239168,\n",
       "         5.87045204,  5.93851239,  6.00657275,  6.0746331 ,  6.14269346,\n",
       "         6.21075381,  6.27881417,  6.34687452,  6.41493488,  6.48299523,\n",
       "         6.55105558,  6.61911594,  6.68717629,  6.75523665,  6.823297  ,\n",
       "         6.89135736,  6.95941771,  7.02747807,  7.09553842,  7.16359878,\n",
       "         7.23165913,  7.29971949,  7.36777984,  7.4358402 ,  7.50390055,\n",
       "         7.57196091,  7.64002126,  7.70808161,  7.77614197,  7.84420232,\n",
       "         7.91226268,  7.98032303,  8.04838339,  8.11644374,  8.1845041 ,\n",
       "         8.25256445,  8.32062481,  8.38868516,  8.45674552,  8.52480587,\n",
       "         8.59286623,  8.66092658,  8.72898694,  8.79704729,  8.86510764,\n",
       "         8.933168  ,  9.00122835,  9.06928871,  9.13734906,  9.20540942,\n",
       "         9.27346977,  9.34153013,  9.40959048,  9.47765084,  9.54571119,\n",
       "         9.61377155,  9.6818319 ,  9.74989226,  9.81795261,  9.88601297,\n",
       "         9.95407332, 10.02213368, 10.09019403, 10.15825438, 10.22631474,\n",
       "        10.29437509, 10.36243545, 10.4304958 , 10.49855616, 10.56661651,\n",
       "        10.63467687]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pltt.hist(np.log(train_df[train_df['Sales']>0]['Sales']), bins=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales  Open\n",
       "0         5263     1\n",
       "1         6064     1\n",
       "2         8314     1\n",
       "3        13995     1\n",
       "4         4822     1\n",
       "...        ...   ...\n",
       "1017204      0     0\n",
       "1017205      0     0\n",
       "1017206      0     0\n",
       "1017207      0     0\n",
       "1017208      0     0\n",
       "\n",
       "[1017209 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['Sales','Open']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales\n",
       "0        172871\n",
       "5674        215\n",
       "5558        197\n",
       "5483        196\n",
       "6049        195\n",
       "          ...  \n",
       "23861         1\n",
       "22756         1\n",
       "24520         1\n",
       "24144         1\n",
       "24287         1\n",
       "Name: count, Length: 21734, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sales'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open\n",
       "1    844392\n",
       "0    172817\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0\n",
       "2   3      7          4  2015-09-17   1.0      1            0              0\n",
       "3   4      8          4  2015-09-17   1.0      1            0              0\n",
       "4   5      9          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        加载数据，设定数值型和非数值型数据\n",
    "    \"\"\"\n",
    "    store = pd.read_csv('./data/store.csv')\n",
    "    train_org = pd.read_csv('./data/train.csv', dtype={'StateHoliday': np.str_})\n",
    "    test_org = pd.read_csv('./data/test.csv', dtype={'StateHoliday': np.str_})\n",
    "    train = pd.merge(train_org, store, on='Store', how='left')\n",
    "    test = pd.merge(test_org,store, on='Store', how='left')\n",
    "    features = test.columns.tolist()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    features_numeric = test.select_dtypes(include=numerics).columns.tolist()\n",
    "    features_non_numeric = [f for f in features if f not in features_numeric]\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据与特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_non_numeric):\n",
    "    \"\"\"\n",
    "        Feature engineering and selection.\n",
    "    \"\"\"\n",
    "    # FEATURE ENGINEERING\n",
    "    train = train[train['Sales'] > 0]\n",
    "\n",
    "    for data in [train,test]:\n",
    "        # year month day\n",
    "        data['year'] = data.Date.apply(lambda x: x.split('-')[0])\n",
    "        data['year'] = data['year'].astype(float)\n",
    "        data['month'] = data.Date.apply(lambda x: x.split('-')[1])\n",
    "        data['month'] = data['month'].astype(float)\n",
    "        data['day'] = data.Date.apply(lambda x: x.split('-')[2])\n",
    "        data['day'] = data['day'].astype(float)\n",
    "\n",
    "        # promo interval \"Jan,Apr,Jul,Oct\"\n",
    "        data['promojan'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jan\" in x else 0)\n",
    "        data['promofeb'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Feb\" in x else 0)\n",
    "        data['promomar'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Mar\" in x else 0)\n",
    "        data['promoapr'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Apr\" in x else 0)\n",
    "        data['promomay'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"May\" in x else 0)\n",
    "        data['promojun'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jun\" in x else 0)\n",
    "        data['promojul'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jul\" in x else 0)\n",
    "        data['promoaug'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Aug\" in x else 0)\n",
    "        data['promosep'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Sep\" in x else 0)\n",
    "        data['promooct'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Oct\" in x else 0)\n",
    "        data['promonov'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Nov\" in x else 0)\n",
    "        data['promodec'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Dec\" in x else 0)\n",
    "\n",
    "    # Features set.\n",
    "    noisy_features = [myid,'Date']\n",
    "    features = [c for c in features if c not in noisy_features]\n",
    "    features_non_numeric = [c for c in features_non_numeric if c not in noisy_features]\n",
    "    features.extend(['year','month','day'])\n",
    "    # Fill NA\n",
    "    class DataFrameImputer(TransformerMixin):\n",
    "        # http://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n",
    "        def __init__(self):\n",
    "            \"\"\"Impute missing values.\n",
    "            Columns of dtype object are imputed with the most frequent value\n",
    "            in column.\n",
    "            Columns of other types are imputed with mean of column.\n",
    "            \"\"\"\n",
    "        def fit(self, X, y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] # mode\n",
    "                if X[c].dtype == np.dtype('O') else X[c].mean() for c in X], # mean\n",
    "                index=X.columns)\n",
    "            return self\n",
    "        def transform(self, X, y=None):\n",
    "            return X.fillna(self.fill)\n",
    "    train = DataFrameImputer().fit_transform(train)\n",
    "    test = DataFrameImputer().fit_transform(test)\n",
    "    # Pre-processing non-numberic values\n",
    "    le = LabelEncoder()\n",
    "    for col in features_non_numeric:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "    # LR和神经网络这种模型都对输入数据的幅度极度敏感，请先做归一化操作\n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_non_numeric) - \\\n",
    "      set([]): # TODO: add what not to scale\n",
    "        scaler.fit(train[col].reshape(-1,1))\n",
    "        train[col] = scaler.transform(train[col].reshape(-1,1))\n",
    "        test[col] = scaler.transform(test[col].reshape(-1,1))\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_native(train,test,features,features_non_numeric):\n",
    "    depth = 13\n",
    "    eta = 0.01\n",
    "    ntrees = 8000\n",
    "    mcw = 3\n",
    "    params = {\"objective\": \"reg:linear\",\n",
    "              \"booster\": \"gbtree\",\n",
    "              \"eta\": eta,\n",
    "              \"max_depth\": depth,\n",
    "              \"min_child_weight\": mcw,\n",
    "              \"subsample\": 0.9,\n",
    "              \"colsample_bytree\": 0.7,\n",
    "              \"silent\": 1\n",
    "              }\n",
    "    print(\"Running with params: \" + str(params))\n",
    "    print(\"Running with ntrees: \" + str(ntrees))\n",
    "    print(\"Running with features: \" + str(features))\n",
    "\n",
    "    # Train model with local split\n",
    "    tsize = 0.05\n",
    "    X_train, X_test = model_selection.train_test_split(train, test_size=tsize)\n",
    "    dtrain = xgb.DMatrix(X_train[features], np.log(X_train[goal] + 1))\n",
    "    dvalid = xgb.DMatrix(X_test[features], np.log(X_test[goal] + 1))\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm = xgb.train(params, dtrain, ntrees, evals=watchlist, early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)\n",
    "    train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "    indices = train_probs < 0\n",
    "    train_probs[indices] = 0\n",
    "    error = rmspe(np.exp(train_probs) - 1, X_test[goal].values)\n",
    "    print(error)\n",
    "\n",
    "    # Predict and Export\n",
    "    test_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "    indices = test_probs < 0\n",
    "    test_probs[indices] = 0\n",
    "    submission = pd.DataFrame({myid: test[myid], goal: np.exp(test_probs) - 1})\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    submission.to_csv(\"./result/dat-xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.csv\" % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)) , index=False)\n",
    "    # Feature importance\n",
    "    if plot:\n",
    "      outfile = open('xgb.fmap', 'w')\n",
    "      i = 0\n",
    "      for feat in features:\n",
    "          outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "          i = i + 1\n",
    "      outfile.close()\n",
    "      importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "      importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "      df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "      df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "      # Plotitup\n",
    "      plt.figure()\n",
    "      df.plot()\n",
    "      df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(25, 15))\n",
    "      plt.title('XGBoost Feature Importance')\n",
    "      plt.xlabel('relative importance')\n",
    "      plt.gcf().savefig('Feature_Importance_xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.png' % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 载入数据中...\n",
      "=> 处理数据与特征工程...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11996\\802817493.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=> 载入数据中...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=> 处理数据与特征工程...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=> 使用XGBoost建模...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mXGB_native\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11996\\613863806.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(train, test, features, features_non_numeric)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# LR和神经网络这种模型都对输入数据的幅度极度敏感，请先做归一化操作\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     for col in set(features) - set(features_non_numeric) - \\\n\u001b[0;32m     63\u001b[0m       \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# TODO: add what not to scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\PythonGPU\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "print(\"=> 载入数据中...\")\n",
    "train,test,features,features_non_numeric = load_data()\n",
    "print(\"=> 处理数据与特征工程...\")\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "print(\"=> 使用XGBoost建模...\")\n",
    "XGB_native(train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
